# prod-llm
While creating genx-studio I learned that it's very difficult to deploy LLMs for real-life applications. This repository will serve as a collection of steps that need to be performed in order to make LLMs usable in the production setting.

Step - 0: Your secure and private coding assistant 
No matter what application you are developing it has now become more important than ever to code the ideas as early as possible BUT while keeping code and data private as well as secure.
For this need, I would recommend you to host a powerful instruct LLM on your local machine.

As of Nov 11 2023 following are the best opensource LM models that you can try out: 
